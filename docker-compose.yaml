version: '3'
services:
  airflow:
    image: apache/airflow:2.7.1
    container_name: airflow_engine
    user: "${AIRFLOW_UID:-50000}:0"
    ports:
      - "8085:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - //var/run/docker.sock:/var/run/docker.sock
      - ./data:/opt/airflow/data
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      # CHANGED: Save DB in the 'data' folder so it persists
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/data/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__WEBSERVER__SECRET_KEY=supersecretkey12345
    # We default to just running the scheduler and webserver
    # We will do the 'init' manually first
    command: bash -c "airflow scheduler & airflow webserver"